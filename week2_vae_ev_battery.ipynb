{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e0d9d6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "                                             # Week 2 â€“ EV Battery Health using Generative AI (VAE)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, backend as K\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loading Dataset\n",
    "file_path = \"ev_battery_charging_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"âœ… Dataset Loaded Successfully!\")\n",
    "print(df.head())\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "\n",
    "# Data Cleaning\n",
    "df = df.dropna()\n",
    "\n",
    "# Encoding categorical columns\n",
    "categorical_cols = ['Charging Mode', 'Battery Type', 'EV Model']\n",
    "encoder = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    df[col] = encoder.fit_transform(df[col])\n",
    "\n",
    "# Droping unnecessary columns (if any non-numeric)\n",
    "df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Step 4: Prepare Data for Model\n",
    "X = df.values\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(\"âœ… Cleaned Dataset Shape:\", X_scaled.shape)\n",
    "\n",
    "input_dim = X_scaled.shape[1]\n",
    "print(\"Input features:\", input_dim)\n",
    "\n",
    "\n",
    "# Build Variational Autoencoder (VAE) - Custom Model\n",
    "\n",
    "\n",
    "latent_dim = 4  # compressed latent space\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.reconstruction_loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data (since it's passed as (x, y) in fit, where x and y are the same for VAE)\n",
    "        x = data[0]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(x)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = self.reconstruction_loss_fn(x, reconstruction)\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            total_loss = reconstruction_loss + tf.reduce_mean(kl_loss)\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "# Define encoder and decoder separately\n",
    "encoder_inputs = keras.Input(shape=(input_dim,))\n",
    "x = layers.Dense(64, activation=\"relu\")(encoder_inputs)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "\n",
    "# Sampling function integrated into encoder output\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = layers.Lambda(sampling, name=\"z\")([z_mean, z_log_var])\n",
    "\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(latent_dim,))\n",
    "d = layers.Dense(32, activation=\"relu\")(decoder_inputs)\n",
    "d = layers.Dense(64, activation=\"relu\")(d)\n",
    "decoder_outputs = layers.Dense(input_dim, activation=\"sigmoid\")(d)\n",
    "decoder = keras.Model(decoder_inputs, decoder_outputs, name=\"decoder\")\n",
    "\n",
    "# Instantiate the custom VAE model\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=\"adam\")\n",
    "vae.summary()\n",
    "\n",
    "# Train the Model\n",
    "history = vae.fit(X_scaled, X_scaled, epochs=50, batch_size=32, verbose=1)\n",
    "vae.save(\"vae_ev_battery_model.h5\")\n",
    "print(\"âœ… Model trained and saved successfully!\")\n",
    "\n",
    "\n",
    "# Visualize Training Progress\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.title(\"VAE Training Loss Curve\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Generate Synthetic Data\n",
    "\n",
    "latent_samples = np.random.normal(size=(10, latent_dim))\n",
    "generated_data = decoder.predict(latent_samples)\n",
    "generated_df = pd.DataFrame(scaler.inverse_transform(generated_data), columns=df.columns)\n",
    "\n",
    "print(\"\\nðŸ§  Sample Synthetic EV Battery Data Generated:\")\n",
    "print(generated_df.head())\n",
    "\n",
    "# Latent Space Visualization\n",
    "\n",
    "latent_representations = encoder.predict(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(latent_representations[:, 0], latent_representations[:, 1], alpha=0.6, c=df['Degradation Rate (%)'], cmap='viridis')\n",
    "plt.colorbar(label='Degradation Rate (%)')\n",
    "plt.title(\"Latent Space Visualization (colored by Degradation Rate)\")\n",
    "plt.xlabel(\"z[0]\")\n",
    "plt.ylabel(\"z[1]\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
